{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# DeepLabCut Toolbox\n",
    "https://github.com/AlexEMG/DeepLabCut\n",
    "\n",
    "This notebook demonstrates the necessary steps to use DeepLabCut for your own project.\n",
    "This shows the most simple code to do so, but many of the functions have additional features, so please check out the overview & the protocol paper!\n",
    "\n",
    "This notebook illustrates how to:\n",
    "- create a project\n",
    "- extract training frames\n",
    "- label the frames\n",
    "- plot the labeled images\n",
    "- create a training set\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- analyze a novel video\n",
    "- create an automatically labeled video \n",
    "- plot the trajectories\n",
    "\n",
    "This notebook demonstrates the necessary steps to use DeepLabCut for your own project.\n",
    "\n",
    "This shows the most simple code to do so, but many of the functions have additional features, so please check out the overview & the protocol paper!\n",
    "\n",
    "Nath\\*, Mathis\\* et al.: Using DeepLabCut for markerless pose estimation during behavior across species. Nature Protocols, 2019.\n",
    "\n",
    "Paper: https://www.nature.com/articles/s41596-019-0176-0\n",
    "\n",
    "Pre-print: https://www.biorxiv.org/content/biorxiv/early/2018/11/24/476531.full.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: this is for use with 3d slices of data in Zimmer lab format \n",
    "\n",
    "This is for use with real WBFM data; for now I don't have annotations, and am just going to make sure the pipeline works for extracting volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "It is always good idea to keep the projects seperate if you want to use different networks to analze your data. You should use one project if you are tracking similar subjects/items even if in different environments. This function creates a new project with sub-directories and a basic configuration file in the user defined directory otherwise the project is created in the current working directory.\n",
    "\n",
    "You can always add new videos (for lableing more data) to the project at any stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DLClight=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "%env DLClight=True\n",
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7"
   },
   "outputs": [],
   "source": [
    "task='WormTest' # Enter the name of your experiment Task\n",
    "experimenter='Charlie' # Enter the name of the experimenter\n",
    "#video=['wb_immobilized/KU20170626-TKU721_nostim_ctrl_w2_part1.ome.tiff'] # Enter the paths of your videos OR FOLDER you want to grab frames from.\n",
    "# video=['/groups/zimmer/Ulises/wbfm/wbfm_december2018/20181220/data/worm1/mCherry/ome']\n",
    "# video=['/users/charles.fieseler/test_worm1_data/mCherry/']\n",
    "\n",
    "# path_config_file=deeplabcut.create_new_project(task,experimenter,video,copy_videos=False, videotype='.tiff') \n",
    "\n",
    "# NOTE: The function returns the path, where your project is. \n",
    "# You could also enter this manually (e.g. if the project is already created and you want to pick up, where you stopped...)\n",
    "# path_config_file = '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-22/config.yaml'\n",
    "path_config_file = '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/config.yaml'\n",
    "#path_config_file = 'C:\\\\Users\\\\charl\\\\Documents\\\\Current_work\\\\DeepLabCut_etc\\\\DeepLabCut-fork\\\\examples\\\\WormTest-Charlie-2020-05-21\\\\config.yaml' # Enter the path of the config file that was just created from the above step (check the folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deeplabcut.create_new_project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/config.yaml\n"
     ]
    }
   ],
   "source": [
    "print(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save individual volumes from ome.tiff movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Basically this is a custom extract_frames() function\n",
    "#\n",
    "\n",
    "from pathlib import Path\n",
    "from deeplabcut.utils import auxiliaryfunctions\n",
    "import tifffile\n",
    "import platform\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_volumes_from_many_files(path_config_file, which_vol=None):\n",
    "    \"\"\"\n",
    "    Assumes a folder of many different volumes, and copies some in the folder given by 'out_folder'\n",
    "    \"\"\"\n",
    "    \n",
    "    if platform.system() is 'Windows':\n",
    "        is_windows = True\n",
    "    else:\n",
    "        is_windows = False\n",
    "    \n",
    "    config_file = Path(path_config_file).resolve()\n",
    "    cfg = auxiliaryfunctions.read_config(config_file)\n",
    "    print(\"Config file read successfully.\")\n",
    "    \n",
    "    video_fnames = [i for i in cfg['video_sets'].keys()]\n",
    "    print(type(video_fnames))\n",
    "    print(\"Found {} volumes.\".format(len(video_fnames)))\n",
    "    \n",
    "    # Read basic metadata\n",
    "    \n",
    "    # Get volume indices to save\n",
    "    if which_vol is None:\n",
    "        which_vol = [0]\n",
    "    \n",
    "    for i_vol in which_vol:\n",
    "        print(\"Reading volume {}/{}\".format(i_vol, len(which_vol)))\n",
    "        \n",
    "        this_fname = video_fnames[i_vol]\n",
    "\n",
    "        # Read and make output name\n",
    "        this_volume = tifffile.imread(this_fname)\n",
    "        output_name = 'img{}.tif'.format(i_vol)\n",
    "\n",
    "        # Save in output folder\n",
    "        fname = Path(video_fnames[0])\n",
    "        output_path = os.path.join(Path(path_config_file).parents[0],'labeled-data',fname.stem)\n",
    "\n",
    "        tifffile.imsave(os.path.join(str(output_path),output_name), this_volume)\n",
    "\n",
    "        print('Saved volume to {}\\\\{}'.format(output_path, output_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "        \n",
    "def extract_volumes_from_MATLAB_output(path_config_file, which_vol=None):\n",
    "    \"\"\"\n",
    "    Takes a video filename, which is a large ome-tiff file, and saves a volume in the folder given by 'out_folder'\n",
    "    \"\"\"\n",
    "    \n",
    "    if platform.system() is 'Windows':\n",
    "        is_windows = True\n",
    "    else:\n",
    "        is_windows = False\n",
    "    \n",
    "    config_file = Path(path_config_file).resolve()\n",
    "    cfg = auxiliaryfunctions.read_config(config_file)\n",
    "    print(\"Config file read successfully.\")\n",
    "    \n",
    "    video_fname = [i for i in cfg['video_sets'].keys()][0] # Assume one video for now (will be giant, ~3GB)\n",
    "    print(video_fname)\n",
    "    \n",
    "    # Read basic metadata to get 'nz' and 'nt'\n",
    "    with tifffile.TiffFile(video_fname) as vid:\n",
    "        #print(tifffile.xml2dict(vid.ome_metadata))\n",
    "        print(vid.ome_metadata)\n",
    "        ome_metadata = vid.ome_metadata\n",
    "        if isinstance(ome_metadata, str):\n",
    "            # Appears to be a bug that just returns a string... can fix manually though\n",
    "            ome_metadata = tifffile.xml2dict(ome_metadata)['OME']\n",
    "        print(ome_metadata.keys())\n",
    "        mdat = ome_metadata['Image']['Pixels']\n",
    "        nz, nt = mdat['SizeZ'], mdat['SizeT']\n",
    "    \n",
    "    # Get volume indices to save\n",
    "    if which_vol is None:\n",
    "        which_vol = [0]\n",
    "    \n",
    "    for i_vol in which_vol:\n",
    "        print(\"Read volume {}/{}\".format(i_vol, len(which_vol)))\n",
    "        \n",
    "        # Convert scalar volume label to the sequential frames\n",
    "        # Note: this may change for future input videos!\n",
    "        vol_indices = list(range(i_vol*nz, i_vol*nz + nz))\n",
    "\n",
    "        # Read and make output name\n",
    "        this_volume = tifffile.imread(video_fname, key=vol_indices)\n",
    "        output_name = 'img{}.tif'.format(i_vol)\n",
    "\n",
    "        # Save in output folder\n",
    "        fname = Path(video_fname)\n",
    "        output_path = os.path.join(Path(path_config_file).parents[0],'labeled-data',fname.stem)\n",
    "\n",
    "        tifffile.imsave(os.path.join(str(output_path),output_name), this_volume)\n",
    "\n",
    "        print('Saved volume to {}\\\\{}'.format(output_path, output_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "        \n",
    "def extract_volumes_from_charlie_output(path_config_file, nz, which_vol=None):\n",
    "    \"\"\"\n",
    "    Takes a video filename, which is a large ome-tiff file, and saves a volume in the folder given by 'out_folder'\n",
    "    \"\"\"\n",
    "    \n",
    "    config_file = Path(path_config_file).resolve()\n",
    "    cfg = auxiliaryfunctions.read_config(config_file)\n",
    "    print(\"Config file read successfully.\")\n",
    "    \n",
    "    video_fname = [i for i in cfg['video_sets'].keys()][0] # Assume one video for now (will be giant, ~3GB)\n",
    "    print(video_fname)\n",
    "    \n",
    "    # Get volume indices to save\n",
    "    if which_vol is None:\n",
    "        which_vol = [0]\n",
    "    \n",
    "    for i_vol in which_vol:\n",
    "        print(\"Read volume {}/{}\".format(i_vol, len(which_vol)))\n",
    "        \n",
    "        # Convert scalar volume label to the sequential frames\n",
    "        # Note: this may change for future input videos!\n",
    "        vol_indices = list(range(i_vol*nz, i_vol*nz + nz))\n",
    "\n",
    "        # Read and make output name\n",
    "        this_volume = tifffile.imread(video_fname, key=vol_indices)\n",
    "        output_name = 'img{}.tif'.format(i_vol)\n",
    "\n",
    "        # Save in output folder\n",
    "        fname = Path(video_fname)\n",
    "        output_path = os.path.join(Path(path_config_file).parents[0],'labeled-data',fname.stem)\n",
    "\n",
    "        tifffile.imsave(os.path.join(str(output_path),output_name), this_volume)\n",
    "\n",
    "        print('Saved volume to {}'.format(os.path.join(output_path, output_name)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "/users/charles.fieseler/test_worm1_data/mCherry/test_100frames.ome.tiff\n",
      "Read volume 1/2\n",
      "Saved volume to /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/labeled-data/test_100frames.ome\\img1.tif\n",
      "Read volume 2/2\n",
      "Saved volume to /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/labeled-data/test_100frames.ome\\img2.tif\n"
     ]
    }
   ],
   "source": [
    "extract_volumes_from_charlie_output(path_config_file, 39, list(range(1,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separately: Manually do BCPD to create the annotations!\n",
    "\n",
    "For now, is completely separate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically update the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpcd_tracker2config_names(path_config_file):\n",
    "    \"\"\"\n",
    "    Automatically updates the config file with the proper number of neurons, and deletes any other default bodyparts.\n",
    "    Only affects the \"bodyparts\" field\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get number of neurons from annotations\n",
    "    home = os.path.dirname(path_config_file)\n",
    "    # TODO: hardcoded folder\n",
    "    annotations_fname = os.path.join(home,'labeled-data', 'test_100frames.ome','CollectedData_Charlie.csv')\n",
    "    df = pd.read_csv(annotations_fname)\n",
    "    num_neurons = int(df.shape[1] / 3)\n",
    "    print(\"Adding body part annotations for {} neurons\".format(num_neurons))\n",
    "#     error()\n",
    "    \n",
    "    # Read in entire config file into a list\n",
    "    config_rows = []\n",
    "    with open(path_config_file) as config:\n",
    "        c_reader = csv.reader(config)#, delimiter=' ')\n",
    "        for row in c_reader:\n",
    "            config_rows.append(row)\n",
    "    \n",
    "    ## Delete the current bodypart lines\n",
    "    delete_these_rows = False\n",
    "    config_rows_edit = config_rows.copy()\n",
    "    for row in config_rows:\n",
    "        if row == ['bodyparts:']:\n",
    "            delete_these_rows = True # Start deleting next row\n",
    "        elif row == ['start: 0']:\n",
    "            delete_these_rows = False # Do not delete this row, or others\n",
    "            break\n",
    "        elif delete_these_rows == True:\n",
    "            # Don't delete either of the two above, but only in between those rows\n",
    "            config_rows_edit.remove(row)\n",
    "    \n",
    "    ## Add in the named neuron lines\n",
    "    # Using \"list slicing\" https://www.geeksforgeeks.org/python-insert-list-in-another-list/\n",
    "    new_names = [['- neuron{}'.format(i)] for i in range(num_neurons)]\n",
    "    insert_index = config_rows_edit.index(['start: 0'])\n",
    "    config_rows_edit[insert_index:insert_index] = new_names\n",
    "    \n",
    "    ## Write the file again\n",
    "    if True:\n",
    "        with open(path_config_file, 'w', newline='') as config:\n",
    "            c_writer = csv.writer(config)\n",
    "            for row in config_rows_edit:\n",
    "                c_writer.writerow(row)\n",
    "    \n",
    "    print(\"Finished! Check the config.yaml file to make sure the bodyparts are properly written\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def wb_tracker2config_names(path_config_file):\n",
    "    \"\"\"\n",
    "    Automatically updates the config file with the proper number of neurons, and deletes any other default bodyparts.\n",
    "    Only affects the \"bodyparts\" field\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get number of neurons from annotations\n",
    "    home = os.path.dirname(path_config_file)\n",
    "    # TODO: hardcoded folder\n",
    "    annotations_fname = os.path.join(home,'labeled-data', 'my-test-annotations','CollectedData_Charlie.csv')\n",
    "#     with h5py.File(annotations_fname, 'r') as ann:\n",
    "#         k = list(ann['df_with_missing']['table'].keys())\n",
    "#         print(k)\n",
    "#         num_neurons = int(len(ann[k[0]])/3)\n",
    "    df = pd.read_csv(annotations_fname)\n",
    "    num_neurons = int(df.shape[1] / 3)\n",
    "    print(\"Adding body part annotations for {} neurons\".format(num_neurons))\n",
    "#     error()\n",
    "    \n",
    "    # Read in entire config file into a list\n",
    "    config_rows = []\n",
    "    with open(path_config_file) as config:\n",
    "        c_reader = csv.reader(config)#, delimiter=' ')\n",
    "        for row in c_reader:\n",
    "            config_rows.append(row)\n",
    "    \n",
    "    ## Delete the current bodypart lines\n",
    "    delete_these_rows = False\n",
    "    config_rows_edit = config_rows.copy()\n",
    "    for row in config_rows:\n",
    "        if row == ['bodyparts:']:\n",
    "            delete_these_rows = True # Start deleting next row\n",
    "        elif row == ['start: 0']:\n",
    "            delete_these_rows = False # Do not delete this row, or others\n",
    "            break\n",
    "        elif delete_these_rows == True:\n",
    "            # Don't delete either of the two above, but only in between those rows\n",
    "            config_rows_edit.remove(row)\n",
    "    \n",
    "    ## Add in the named neuron lines\n",
    "    # Using \"list slicing\" https://www.geeksforgeeks.org/python-insert-list-in-another-list/\n",
    "    new_names = [['- neuron{}'.format(i)] for i in range(num_neurons)]\n",
    "    insert_index = config_rows_edit.index(['start: 0'])\n",
    "    config_rows_edit[insert_index:insert_index] = new_names\n",
    "    \n",
    "    ## Write the file again\n",
    "    if True:\n",
    "        with open(path_config_file, 'w', newline='') as config:\n",
    "            c_writer = csv.writer(config)\n",
    "            for row in config_rows_edit:\n",
    "                c_writer.writerow(row)\n",
    "    #for row in config_rows_edit:\n",
    "        #c_writer.writerow(row)\n",
    "     #   print(row[:])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding body part annotations for 113 neurons\n",
      "Finished! Check the config.yaml file to make sure the bodyparts are properly written\n"
     ]
    }
   ],
   "source": [
    "bpcd_tracker2config_names(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vim95ZvkPSeN"
   },
   "source": [
    "## Check the labels\n",
    "\n",
    "[OPTIONAL] Checking if the labels were created and stored correctly is beneficial for training, since labeling is one of the most critical parts for creating the training dataset. The DeepLabCut toolbox provides a function `check\\_labels'  to do so. It is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Charlie.\n",
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/labeled-data/test_100frames.ome_labeled  already exists!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 678 into shape (2,newaxis,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-41f1e06c018e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#this creates a subdirectory with the frames + your labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DeepLabCut-dev/DeepLabCut/deeplabcut/generate_training_dataset/trainingsetmanipulation.py\u001b[0m in \u001b[0;36mcheck_labels\u001b[0;34m(config, Labels, scale, dpi, draw_skeleton, visualizeindividuals)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0mkeypoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m                 \u001b[0mdraw_skeleton\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdraw_skeleton\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 \u001b[0mcolor_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_by\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m             )\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLabCut-dev/DeepLabCut/deeplabcut/utils/visualization.py\u001b[0m in \u001b[0;36mmake_labeled_images_from_dataframe\u001b[0;34m(df, cfg, destfolder, scale, dpi, keypoint, draw_skeleton, color_by)\u001b[0m\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m     \u001b[0mscat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m     \u001b[0msegs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_bones\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0mcoll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLineCollection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skeleton_color\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alphavalue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 678 into shape (2,newaxis,2)"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of87fOjgPqzH"
   },
   "source": [
    "If the labels need adjusted, you can use relauch the labeling GUI to move them around, save, and re-plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "\n",
    "This function generates the training data information for network training based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles if they want to benchmark the performance (typcailly, 1 is what you will set, so you pass nothing!). \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**. For most all use cases we have seen, the defaults are perfectly fine.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DLClight=True\n"
     ]
    }
   ],
   "source": [
    "# IF THE KERNEL IS RESET\n",
    "%env DLClight=True\n",
    "import deeplabcut\n",
    "# path_config_file = '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-22/config.yaml'\n",
    "#path_config_file = 'C:\\\\Users\\\\charl\\\\Documents\\\\Current_work\\\\DeepLabCut_etc\\\\DeepLabCut-fork\\\\examples\\\\WormTest-Charlie-2020-05-21\\\\config.yaml' # Enter the path of the config file that was just created from the above step (check the folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/training-datasets/iteration-0/UnaugmentedDataSet_WormTestJun25  already exists!\n",
      "Recognized z-slice training data; using custom function\n",
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/dlc-models/iteration-0/WormTestJun25-trainset95shuffle1  already exists!\n",
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/dlc-models/iteration-0/WormTestJun25-trainset95shuffle1/train  already exists!\n",
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/dlc-models/iteration-0/WormTestJun25-trainset95shuffle1/test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95, 1, (array([1]), array([0])))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)\n",
    "#remember, there are several networks you can pick, the default is resnet-50!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training:\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_pOvDq_2oEJW",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18],\n",
      "                [19],\n",
      "                [20],\n",
      "                [21],\n",
      "                [22],\n",
      "                [23],\n",
      "                [24],\n",
      "                [25],\n",
      "                [26],\n",
      "                [27],\n",
      "                [28],\n",
      "                [29],\n",
      "                [30],\n",
      "                [31],\n",
      "                [32],\n",
      "                [33],\n",
      "                [34],\n",
      "                [35],\n",
      "                [36],\n",
      "                [37],\n",
      "                [38],\n",
      "                [39],\n",
      "                [40],\n",
      "                [41],\n",
      "                [42],\n",
      "                [43],\n",
      "                [44],\n",
      "                [45],\n",
      "                [46],\n",
      "                [47],\n",
      "                [48],\n",
      "                [49],\n",
      "                [50],\n",
      "                [51],\n",
      "                [52],\n",
      "                [53],\n",
      "                [54],\n",
      "                [55],\n",
      "                [56],\n",
      "                [57],\n",
      "                [58],\n",
      "                [59],\n",
      "                [60],\n",
      "                [61],\n",
      "                [62],\n",
      "                [63],\n",
      "                [64],\n",
      "                [65],\n",
      "                [66],\n",
      "                [67],\n",
      "                [68],\n",
      "                [69],\n",
      "                [70],\n",
      "                [71],\n",
      "                [72],\n",
      "                [73],\n",
      "                [74],\n",
      "                [75],\n",
      "                [76],\n",
      "                [77],\n",
      "                [78],\n",
      "                [79],\n",
      "                [80],\n",
      "                [81],\n",
      "                [82],\n",
      "                [83],\n",
      "                [84],\n",
      "                [85],\n",
      "                [86],\n",
      "                [87],\n",
      "                [88],\n",
      "                [89],\n",
      "                [90],\n",
      "                [91],\n",
      "                [92],\n",
      "                [93],\n",
      "                [94],\n",
      "                [95],\n",
      "                [96],\n",
      "                [97],\n",
      "                [98],\n",
      "                [99],\n",
      "                [100],\n",
      "                [101],\n",
      "                [102],\n",
      "                [103],\n",
      "                [104],\n",
      "                [105],\n",
      "                [106],\n",
      "                [107],\n",
      "                [108],\n",
      "                [109],\n",
      "                [110],\n",
      "                [111],\n",
      "                [112]],\n",
      " 'all_joints_names': ['neuron0',\n",
      "                      'neuron1',\n",
      "                      'neuron2',\n",
      "                      'neuron3',\n",
      "                      'neuron4',\n",
      "                      'neuron5',\n",
      "                      'neuron6',\n",
      "                      'neuron7',\n",
      "                      'neuron8',\n",
      "                      'neuron9',\n",
      "                      'neuron10',\n",
      "                      'neuron11',\n",
      "                      'neuron12',\n",
      "                      'neuron13',\n",
      "                      'neuron14',\n",
      "                      'neuron15',\n",
      "                      'neuron16',\n",
      "                      'neuron17',\n",
      "                      'neuron18',\n",
      "                      'neuron19',\n",
      "                      'neuron20',\n",
      "                      'neuron21',\n",
      "                      'neuron22',\n",
      "                      'neuron23',\n",
      "                      'neuron24',\n",
      "                      'neuron25',\n",
      "                      'neuron26',\n",
      "                      'neuron27',\n",
      "                      'neuron28',\n",
      "                      'neuron29',\n",
      "                      'neuron30',\n",
      "                      'neuron31',\n",
      "                      'neuron32',\n",
      "                      'neuron33',\n",
      "                      'neuron34',\n",
      "                      'neuron35',\n",
      "                      'neuron36',\n",
      "                      'neuron37',\n",
      "                      'neuron38',\n",
      "                      'neuron39',\n",
      "                      'neuron40',\n",
      "                      'neuron41',\n",
      "                      'neuron42',\n",
      "                      'neuron43',\n",
      "                      'neuron44',\n",
      "                      'neuron45',\n",
      "                      'neuron46',\n",
      "                      'neuron47',\n",
      "                      'neuron48',\n",
      "                      'neuron49',\n",
      "                      'neuron50',\n",
      "                      'neuron51',\n",
      "                      'neuron52',\n",
      "                      'neuron53',\n",
      "                      'neuron54',\n",
      "                      'neuron55',\n",
      "                      'neuron56',\n",
      "                      'neuron57',\n",
      "                      'neuron58',\n",
      "                      'neuron59',\n",
      "                      'neuron60',\n",
      "                      'neuron61',\n",
      "                      'neuron62',\n",
      "                      'neuron63',\n",
      "                      'neuron64',\n",
      "                      'neuron65',\n",
      "                      'neuron66',\n",
      "                      'neuron67',\n",
      "                      'neuron68',\n",
      "                      'neuron69',\n",
      "                      'neuron70',\n",
      "                      'neuron71',\n",
      "                      'neuron72',\n",
      "                      'neuron73',\n",
      "                      'neuron74',\n",
      "                      'neuron75',\n",
      "                      'neuron76',\n",
      "                      'neuron77',\n",
      "                      'neuron78',\n",
      "                      'neuron79',\n",
      "                      'neuron80',\n",
      "                      'neuron81',\n",
      "                      'neuron82',\n",
      "                      'neuron83',\n",
      "                      'neuron84',\n",
      "                      'neuron85',\n",
      "                      'neuron86',\n",
      "                      'neuron87',\n",
      "                      'neuron88',\n",
      "                      'neuron89',\n",
      "                      'neuron90',\n",
      "                      'neuron91',\n",
      "                      'neuron92',\n",
      "                      'neuron93',\n",
      "                      'neuron94',\n",
      "                      'neuron95',\n",
      "                      'neuron96',\n",
      "                      'neuron97',\n",
      "                      'neuron98',\n",
      "                      'neuron99',\n",
      "                      'neuron100',\n",
      "                      'neuron101',\n",
      "                      'neuron102',\n",
      "                      'neuron103',\n",
      "                      'neuron104',\n",
      "                      'neuron105',\n",
      "                      'neuron106',\n",
      "                      'neuron107',\n",
      "                      'neuron108',\n",
      "                      'neuron109',\n",
      "                      'neuron110',\n",
      "                      'neuron111',\n",
      "                      'neuron112'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_WormTestJun25/WormTest_Charlie95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_WormTestJun25/Documentation_data-WormTest_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 113,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/dlc-models/iteration-0/WormTestJun25-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Switching batchsize to 1, as default/tensorpack/deterministic loaders do not support batches >1. Use imgaug loader.\n",
      "Starting with standard pose-dataset loader.\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Display_iters overwritten as 50\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/dlc-models/iteration-0/WormTestJun25-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'weigh_only_present_joints': False, 'pairwise_huber_loss': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111], [112]], 'all_joints_names': ['neuron0', 'neuron1', 'neuron2', 'neuron3', 'neuron4', 'neuron5', 'neuron6', 'neuron7', 'neuron8', 'neuron9', 'neuron10', 'neuron11', 'neuron12', 'neuron13', 'neuron14', 'neuron15', 'neuron16', 'neuron17', 'neuron18', 'neuron19', 'neuron20', 'neuron21', 'neuron22', 'neuron23', 'neuron24', 'neuron25', 'neuron26', 'neuron27', 'neuron28', 'neuron29', 'neuron30', 'neuron31', 'neuron32', 'neuron33', 'neuron34', 'neuron35', 'neuron36', 'neuron37', 'neuron38', 'neuron39', 'neuron40', 'neuron41', 'neuron42', 'neuron43', 'neuron44', 'neuron45', 'neuron46', 'neuron47', 'neuron48', 'neuron49', 'neuron50', 'neuron51', 'neuron52', 'neuron53', 'neuron54', 'neuron55', 'neuron56', 'neuron57', 'neuron58', 'neuron59', 'neuron60', 'neuron61', 'neuron62', 'neuron63', 'neuron64', 'neuron65', 'neuron66', 'neuron67', 'neuron68', 'neuron69', 'neuron70', 'neuron71', 'neuron72', 'neuron73', 'neuron74', 'neuron75', 'neuron76', 'neuron77', 'neuron78', 'neuron79', 'neuron80', 'neuron81', 'neuron82', 'neuron83', 'neuron84', 'neuron85', 'neuron86', 'neuron87', 'neuron88', 'neuron89', 'neuron90', 'neuron91', 'neuron92', 'neuron93', 'neuron94', 'neuron95', 'neuron96', 'neuron97', 'neuron98', 'neuron99', 'neuron100', 'neuron101', 'neuron102', 'neuron103', 'neuron104', 'neuron105', 'neuron106', 'neuron107', 'neuron108', 'neuron109', 'neuron110', 'neuron111', 'neuron112'], 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_WormTestJun25/WormTest_Charlie95shuffle1.mat', 'display_iters': 1000, 'init_weights': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_WormTestJun25/Documentation_data-WormTest_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 113, 'pos_dist_thresh': 17, 'project_path': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 50 loss: 0.2185 lr: 0.005\n",
      "iteration: 100 loss: 0.0320 lr: 0.005\n",
      "iteration: 150 loss: 0.0333 lr: 0.005\n",
      "iteration: 200 loss: 0.0341 lr: 0.005\n",
      "iteration: 250 loss: 0.0333 lr: 0.005\n",
      "iteration: 300 loss: 0.0310 lr: 0.005\n",
      "iteration: 350 loss: 0.0328 lr: 0.005\n",
      "iteration: 400 loss: 0.0325 lr: 0.005\n",
      "iteration: 450 loss: 0.0350 lr: 0.005\n",
      "iteration: 500 loss: 0.0338 lr: 0.005\n",
      "iteration: 550 loss: 0.0332 lr: 0.005\n",
      "iteration: 600 loss: 0.0322 lr: 0.005\n",
      "iteration: 650 loss: 0.0312 lr: 0.005\n",
      "iteration: 700 loss: 0.0309 lr: 0.005\n",
      "iteration: 750 loss: 0.0332 lr: 0.005\n",
      "iteration: 800 loss: 0.0318 lr: 0.005\n",
      "iteration: 850 loss: 0.0324 lr: 0.005\n",
      "iteration: 900 loss: 0.0304 lr: 0.005\n",
      "iteration: 950 loss: 0.0323 lr: 0.005\n",
      "iteration: 1000 loss: 0.0313 lr: 0.005\n",
      "iteration: 1050 loss: 0.0316 lr: 0.005\n",
      "iteration: 1100 loss: 0.0315 lr: 0.005\n",
      "iteration: 1150 loss: 0.0322 lr: 0.005\n",
      "iteration: 1200 loss: 0.0304 lr: 0.005\n",
      "iteration: 1250 loss: 0.0312 lr: 0.005\n",
      "iteration: 1300 loss: 0.0338 lr: 0.005\n",
      "iteration: 1350 loss: 0.0316 lr: 0.005\n",
      "iteration: 1400 loss: 0.0331 lr: 0.005\n",
      "iteration: 1450 loss: 0.0334 lr: 0.005\n",
      "iteration: 1500 loss: 0.0305 lr: 0.005\n",
      "iteration: 1550 loss: 0.0310 lr: 0.005\n",
      "iteration: 1600 loss: 0.0317 lr: 0.005\n",
      "iteration: 1650 loss: 0.0338 lr: 0.005\n",
      "iteration: 1700 loss: 0.0322 lr: 0.005\n",
      "iteration: 1750 loss: 0.0298 lr: 0.005\n",
      "iteration: 1800 loss: 0.0352 lr: 0.005\n",
      "iteration: 1850 loss: 0.0310 lr: 0.005\n",
      "iteration: 1900 loss: 0.0322 lr: 0.005\n",
      "iteration: 1950 loss: 0.0331 lr: 0.005\n",
      "iteration: 2000 loss: 0.0306 lr: 0.005\n",
      "iteration: 2050 loss: 0.0317 lr: 0.005\n",
      "iteration: 2100 loss: 0.0303 lr: 0.005\n",
      "iteration: 2150 loss: 0.0319 lr: 0.005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-555b4ce551a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplayiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             )  # pass on path and file name for pose_cfg.yaml!\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    252\u001b[0m         [_, loss_val, summary] = sess.run(\n\u001b[1;32m    253\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_summaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_lr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         )\n\u001b[1;32m    256\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file, displayiters=50, saveiters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DLClight=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "# IF THE KERNEL IS RESET\n",
    "%env DLClight=True\n",
    "import deeplabcut\n",
    "path_config_file = '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-12/config.yaml'\n",
    "\n",
    "#path_config_file = 'C:\\\\Users\\\\charl\\\\Documents\\\\Current_work\\\\DeepLabCut_etc\\\\DeepLabCut-fork\\\\examples\\\\WormTest-Charlie-2020-05-21\\\\config.yaml' # Enter the path of the config file that was just created from the above step (check the folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nv4zlbrnoEJg",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18],\n",
      "                [19],\n",
      "                [20],\n",
      "                [21],\n",
      "                [22],\n",
      "                [23],\n",
      "                [24],\n",
      "                [25],\n",
      "                [26],\n",
      "                [27],\n",
      "                [28],\n",
      "                [29],\n",
      "                [30],\n",
      "                [31],\n",
      "                [32],\n",
      "                [33],\n",
      "                [34],\n",
      "                [35],\n",
      "                [36],\n",
      "                [37],\n",
      "                [38],\n",
      "                [39],\n",
      "                [40],\n",
      "                [41],\n",
      "                [42],\n",
      "                [43],\n",
      "                [44],\n",
      "                [45],\n",
      "                [46],\n",
      "                [47],\n",
      "                [48],\n",
      "                [49],\n",
      "                [50],\n",
      "                [51],\n",
      "                [52],\n",
      "                [53],\n",
      "                [54],\n",
      "                [55],\n",
      "                [56],\n",
      "                [57],\n",
      "                [58],\n",
      "                [59],\n",
      "                [60],\n",
      "                [61],\n",
      "                [62],\n",
      "                [63],\n",
      "                [64],\n",
      "                [65],\n",
      "                [66],\n",
      "                [67],\n",
      "                [68],\n",
      "                [69],\n",
      "                [70],\n",
      "                [71],\n",
      "                [72],\n",
      "                [73],\n",
      "                [74],\n",
      "                [75],\n",
      "                [76],\n",
      "                [77],\n",
      "                [78],\n",
      "                [79],\n",
      "                [80],\n",
      "                [81],\n",
      "                [82],\n",
      "                [83],\n",
      "                [84],\n",
      "                [85],\n",
      "                [86],\n",
      "                [87],\n",
      "                [88],\n",
      "                [89],\n",
      "                [90],\n",
      "                [91],\n",
      "                [92],\n",
      "                [93],\n",
      "                [94],\n",
      "                [95],\n",
      "                [96],\n",
      "                [97],\n",
      "                [98],\n",
      "                [99],\n",
      "                [100],\n",
      "                [101],\n",
      "                [102],\n",
      "                [103],\n",
      "                [104],\n",
      "                [105],\n",
      "                [106],\n",
      "                [107],\n",
      "                [108],\n",
      "                [109],\n",
      "                [110],\n",
      "                [111],\n",
      "                [112]],\n",
      " 'all_joints_names': ['neuron0',\n",
      "                      'neuron1',\n",
      "                      'neuron2',\n",
      "                      'neuron3',\n",
      "                      'neuron4',\n",
      "                      'neuron5',\n",
      "                      'neuron6',\n",
      "                      'neuron7',\n",
      "                      'neuron8',\n",
      "                      'neuron9',\n",
      "                      'neuron10',\n",
      "                      'neuron11',\n",
      "                      'neuron12',\n",
      "                      'neuron13',\n",
      "                      'neuron14',\n",
      "                      'neuron15',\n",
      "                      'neuron16',\n",
      "                      'neuron17',\n",
      "                      'neuron18',\n",
      "                      'neuron19',\n",
      "                      'neuron20',\n",
      "                      'neuron21',\n",
      "                      'neuron22',\n",
      "                      'neuron23',\n",
      "                      'neuron24',\n",
      "                      'neuron25',\n",
      "                      'neuron26',\n",
      "                      'neuron27',\n",
      "                      'neuron28',\n",
      "                      'neuron29',\n",
      "                      'neuron30',\n",
      "                      'neuron31',\n",
      "                      'neuron32',\n",
      "                      'neuron33',\n",
      "                      'neuron34',\n",
      "                      'neuron35',\n",
      "                      'neuron36',\n",
      "                      'neuron37',\n",
      "                      'neuron38',\n",
      "                      'neuron39',\n",
      "                      'neuron40',\n",
      "                      'neuron41',\n",
      "                      'neuron42',\n",
      "                      'neuron43',\n",
      "                      'neuron44',\n",
      "                      'neuron45',\n",
      "                      'neuron46',\n",
      "                      'neuron47',\n",
      "                      'neuron48',\n",
      "                      'neuron49',\n",
      "                      'neuron50',\n",
      "                      'neuron51',\n",
      "                      'neuron52',\n",
      "                      'neuron53',\n",
      "                      'neuron54',\n",
      "                      'neuron55',\n",
      "                      'neuron56',\n",
      "                      'neuron57',\n",
      "                      'neuron58',\n",
      "                      'neuron59',\n",
      "                      'neuron60',\n",
      "                      'neuron61',\n",
      "                      'neuron62',\n",
      "                      'neuron63',\n",
      "                      'neuron64',\n",
      "                      'neuron65',\n",
      "                      'neuron66',\n",
      "                      'neuron67',\n",
      "                      'neuron68',\n",
      "                      'neuron69',\n",
      "                      'neuron70',\n",
      "                      'neuron71',\n",
      "                      'neuron72',\n",
      "                      'neuron73',\n",
      "                      'neuron74',\n",
      "                      'neuron75',\n",
      "                      'neuron76',\n",
      "                      'neuron77',\n",
      "                      'neuron78',\n",
      "                      'neuron79',\n",
      "                      'neuron80',\n",
      "                      'neuron81',\n",
      "                      'neuron82',\n",
      "                      'neuron83',\n",
      "                      'neuron84',\n",
      "                      'neuron85',\n",
      "                      'neuron86',\n",
      "                      'neuron87',\n",
      "                      'neuron88',\n",
      "                      'neuron89',\n",
      "                      'neuron90',\n",
      "                      'neuron91',\n",
      "                      'neuron92',\n",
      "                      'neuron93',\n",
      "                      'neuron94',\n",
      "                      'neuron95',\n",
      "                      'neuron96',\n",
      "                      'neuron97',\n",
      "                      'neuron98',\n",
      "                      'neuron99',\n",
      "                      'neuron100',\n",
      "                      'neuron101',\n",
      "                      'neuron102',\n",
      "                      'neuron103',\n",
      "                      'neuron104',\n",
      "                      'neuron105',\n",
      "                      'neuron106',\n",
      "                      'neuron107',\n",
      "                      'neuron108',\n",
      "                      'neuron109',\n",
      "                      'neuron110',\n",
      "                      'neuron111',\n",
      "                      'neuron112'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_WormTestJun25/WormTest_Charlie95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_WormTestJun25/Documentation_data-WormTest_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 113,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/dlc-models/iteration-0/WormTestJun25-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/evaluation-results/  already exists!\n",
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/evaluation-results/iteration-0/WormTestJun25-trainset95shuffle1  already exists!\n",
      "Running  DLC_resnet50_WormTestJun25shuffle1_2000  with # of trainingiterations: 2000\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  4.57it/s]\n",
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/evaluate.py:857: RuntimeWarning: Mean of empty slice\n",
      "  RMSEpcutoff.iloc[testIndices].values.flatten()\n",
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/evaluate.py:860: RuntimeWarning: Mean of empty slice\n",
      "  RMSEpcutoff.iloc[trainIndices].values.flatten()\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-2000\n",
      "Results for 2000  training iterations: 95 1 train error: 534.89 pixels. Test error: 550.41  pixels.\n",
      "With pcutoff of 0.6  train error: nan pixels. Test error: nan pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:02<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file, plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-11000 for model /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-12/dlc-models/iteration-0/WormTestJun12-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "No video(s) were found. Please check your paths and/or 'video_type'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_WormTestJun12shuffle1_11000'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videofile_path = ['videos/video3.avi','videos/video4.avi'] #Enter a folder OR a list of videos to analyze.\n",
    "\n",
    "deeplabcut.analyze_videos(path_config_file,videofile_path, videotype='.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [optional step]\n",
    "\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. This step has many options, so please look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file,['/videos/video3.avi']) #pass a specific video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [],
   "source": [
    "%gui wx\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Afterwards, if you want to look at the adjusted frames, you can load them in the main GUI by running: ``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "(you can add a new \"cell\" below to add this code!)\n",
    "\n",
    "#### Once all folders are relabeled, check the labels again! If you are not happy, adjust them in the main GUI:\n",
    "\n",
    "``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "Check Labels:\n",
    "\n",
    "``deeplabcut.check_labels(path_config_file)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [],
   "source": [
    "#NOW, merge this with your original data:\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refinement of labels and appending them to the original dataset, this creates a new iteration of training dataset. This is automatically set in the config.yaml file, so let's get training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7"
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. \n",
    "\n",
    "THIS HAS MANY FUN OPTIONS! \n",
    "\n",
    "``deeplabcut.create_labeled_video(config, videos, videotype='avi', shuffle=1, trainingsetindex=0, filtered=False, save_frames=False, Frames2plot=None, delete=False, displayedbodyparts='all', codec='mp4v', outputframerate=None, destfolder=None, draw_skeleton=False, trailpoints=0, displaycropped=False)``\n",
    "\n",
    "So please check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE"
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(path_config_file,videofile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,videofile_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-DLC-GPU-dev]",
   "language": "python",
   "name": "conda-env-.conda-DLC-GPU-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
